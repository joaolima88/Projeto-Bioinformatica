{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "ATENÇÃO - criar o ambiente adequado antes de correr este script (consultar o github do evo para mais detalhes - https://github.com/evo-design/evo)\n",
    "\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "bash Miniconda3-latest-Linux-x86_64.sh -b -p $HOME/miniconda\n",
    "source $HOME/miniconda/bin/activate\n",
    "conda create -n evo_project python=3.9 -y\n",
    "conda activate evo_project\n",
    "module load cuda\n",
    "conda install pytorch torchvision pytorch-cuda=12.1 -c pytorch -c nvidia -y\n",
    "pip install evo-model pandas scikit-learn -y\n",
    "\n",
    "\n",
    "\n",
    "Script de Treinamento de SVM para Regressão.\n",
    "Este script utiliza o modelo EVO como extrator de features para otimizar\n",
    "construções de DNA para expressão génica.\n",
    "\"\"\"\n",
    "\n",
    "# --- 0. Importações de Bibliotecas ---\n",
    "# pré-instalar as bibliotecas no ambiente Python adequado.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import gc # Módulo útil para gerir a memória\n",
    "\n",
    "# Importar a classe Evo.\n",
    "try:\n",
    "    from evo.models import Evo\n",
    "    print(\"Módulo 'evo.models.Evo' importado com sucesso.\")\n",
    "except ImportError:\n",
    "    print(\"ERRO: O módulo 'evo.models.Evo' não foi encontrado. Verifique que se 'evo-model' está instalado corretamente no ambiente.\")\n",
    "    sys.exit(1) # Sair se a biblioteca essencial não estiver disponível\n",
    "\n",
    "# Ativar computação TensorFloat32 para speedups em GPUs NVIDIA compatíveis.\n",
    "# Pode acelerar as operações de matriz sem perda significativa de precisão.\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "print(\"TensorFloat32 ativado para operações de matriz CUDA.\")\n",
    "\n",
    "\n",
    "\n",
    "# --- 1. Configurações Iniciais ---\n",
    "# Definir o dispositivo de execução (GPU ou CPU).\n",
    "# Dá prioridade ao GPU se disponível para aceleração computacional.\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"\\ndispositivo = {device}.\")\n",
    "if device == 'cpu':\n",
    "    print(\"AVISO: GPU não disponível. A execução na CPU será significativamente mais lenta.\")\n",
    "\n",
    "\n",
    "# Caminho completo para o dataset de treino.\n",
    "TRAINING_DATA_FILE = os.path.expanduser('~/projeto/data/training_data.csv')\n",
    "\n",
    "# Diretório para salvar e carregar os embeddings do EVO.\n",
    "# Permite reutilizar embeddings se estes já foram pré-calculados, economiza tempo em execuções futuras.\n",
    "DATA_PATH_FOR_EMBEDDINGS = os.path.dirname(TRAINING_DATA_FILE)\n",
    "EVO_EMBEDDINGS_FILE = os.path.join(DATA_PATH_FOR_EMBEDDINGS, 'evo_embeddings.npy')\n",
    "\n",
    "\"\"\"\n",
    "Nome do modelo EVO a ser carregado.\n",
    "Outros modelos disponíveis: evo-1.5-8k-base, evo-1-131-base, evo-1-8k-crispr e evo-1-8k-transposon\n",
    "aqui só nos interessa o evo-1-8k-base, evo-1.5-8k-base e o evo-1-131-base\n",
    "\"\"\"\n",
    "EVO_MODEL_NAME = \"evo-1-8k-base\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Tamanho do lote (batch size) para a extração de features do EVO.\n",
    "O batch size afeta principalmente a quantidade de memória necessária\n",
    "para as ativações durante a inferência.\n",
    "Um valor maior acelera a inferência na GPU, mas requer mais VRAM.\n",
    "Ajustar o valor com base na VRAM disponível na GPU\n",
    "O evo-1-8k-base tem ~ 6.45 mil milhões de parâmetros.\n",
    "mesmo em precisão mista (FP16/BF16), ele ocupa ~ 12.9 GiB de VRAM apenas para os pesos\n",
    "mínimo recomendado seria 16-24 GiB (para além dos 12.9 GiB precisa-mos de memória para o PyTorch)\n",
    "\"\"\"\n",
    "EVO_BATCH_SIZE = 1\n",
    "\n",
    "\n",
    "\n",
    "# --- 2. Carregar os Dados ---\n",
    "# Carrega o dataset de treino, que contém as sequências de DNA e os valores de expressão.\n",
    "try:\n",
    "    df = pd.read_csv(TRAINING_DATA_FILE)\n",
    "    print(f\"\\nDados carregados com sucesso de {TRAINING_DATA_FILE}. Dimensão: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: O arquivo de dados '{TRAINING_DATA_FILE}' não foi encontrado.\")\n",
    "    print(f\"Verifique o caminho do arquivo.\")\n",
    "    sys.exit(1) # Sair se o arquivo não for encontrado\n",
    "\n",
    "# Verifica se o DataFrame contém as colunas esperadas ('target', 'sequence', 'prot_z').\n",
    "# 'target' é o ID do construct, 'sequence' é a sequência de DNA, e 'prot_z' é a expressão proteica normalizada.\n",
    "if not all(col in df.columns for col in ['target', 'sequence', 'prot_z']):\n",
    "    print(\"ERRO: colunas inesperadas no Dataframe.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Extrai as sequências e os valores de expressão para uso no pipeline.\n",
    "sequences = df['sequence'].tolist()\n",
    "prot_z = df['prot_z'].values\n",
    "\n",
    "\n",
    "\n",
    "# --- 3. Função para Extrair Features do EVO ---\n",
    "def extract_evo_features(sequences: list, model, tokenizer, device: str, batch_size: int):\n",
    "    \"\"\"\n",
    "    Extrai embeddings de sequência usando o modelo EVO.\n",
    "    Estes embeddings servem como features de entrada para o modelo SVM.\n",
    "    O modelo EVO retorna (logits, hidden_states), e a média dos hidden_states\n",
    "    da última camada é usada como o embedding da sequência.\n",
    "    \"\"\"\n",
    "    print(f\"\\nExtraindo features do EVO para {len(sequences)} sequências com batch_size={batch_size}...\")\n",
    "    model.eval() # Coloca o modelo em modo de avaliação (desativa dropout, etc.)\n",
    "    all_embeddings = []\n",
    "\n",
    "    # Processa as sequências em lotes para gerenciar eficientemente a memória.\n",
    "    for i in range(0, len(sequences), batch_size):\n",
    "        batch_sequences = sequences[i:i + batch_size]\n",
    "\n",
    "        # Encontra o comprimento máximo da sequência no lote para aplicar padding.\n",
    "        max_seq_length = max(len(seq) for seq in batch_sequences)\n",
    "        input_ids_batch = []\n",
    "        for seq in batch_sequences:\n",
    "            # Tokeniza a sequência de DNA.\n",
    "            tokenized_seq = tokenizer.tokenize(seq)\n",
    "            # Adiciona padding ao final para igualar o comprimento do lote.\n",
    "            padding_needed = max_seq_length - len(tokenized_seq)\n",
    "            padded_tokenized_seq = tokenized_seq + [tokenizer.pad_id] * padding_needed\n",
    "            input_ids_batch.append(padded_tokenized_seq)\n",
    "\n",
    "        # Converte a lista de IDs de token para um tensor PyTorch e move para o dispositivo.\n",
    "        input_ids = torch.tensor(input_ids_batch, dtype=torch.long).to(device)\n",
    "\n",
    "        with torch.no_grad(): # Desativa o cálculo de gradientes para economizar memória e acelerar a inferência.\n",
    "            # Realiza a inferência com o modelo EVO.\n",
    "            logits, hidden_states = model(input_ids)\n",
    "\n",
    "            # Calcula o embedding da sequência fazendo a média dos hidden_states da última camada.\n",
    "            # hidden_states[0] geralmente contém a saída da última camada antes do layer norm final.\n",
    "            sequence_embeddings = hidden_states[0].mean(dim=1)\n",
    "\n",
    "            # Move os embeddings para a CPU e converte para NumPy array.\n",
    "            all_embeddings.append(sequence_embeddings.cpu().numpy())\n",
    "\n",
    "        print(f\"  Processado {min(i + batch_size, len(sequences))}/{len(sequences)} sequências...\")\n",
    "        # Força a recolha de lixo e esvazia a cache da GPU para liberar memória.\n",
    "        gc.collect()\n",
    "        if device == 'cuda:0':\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # Empilha todos os embeddings processados em um único array NumPy.\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "\n",
    "\n",
    "# --- 4. Carregar Modelo EVO e Extrair Features ---\n",
    "# Esta secção gere o carregamento do modelo EVO e a obtenção das features.\n",
    "evo_features = None\n",
    "\n",
    "# Tenta carregar embeddings pré-calculados do disco para economizar tempo.\n",
    "if os.path.exists(EVO_EMBEDDINGS_FILE):\n",
    "    try:\n",
    "        loaded_embeddings = np.load(EVO_EMBEDDINGS_FILE)\n",
    "        # Verifica se os embeddings carregados correspondem ao dataset atual.\n",
    "        if loaded_embeddings.shape[0] == len(sequences):\n",
    "            evo_features = loaded_embeddings\n",
    "            print(f\"\\nCarregando embeddings do EVO de {EVO_EMBEDDINGS_FILE}. Dimensão: {evo_features.shape}\")\n",
    "        else:\n",
    "            print(f\"\\nAviso: Embeddings carregados ({loaded_embeddings.shape[0]} sequências) não correspondem ao dataset atual ({len(sequences)} sequências). Recalculando.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nErro ao carregar embeddings de {EVO_EMBEDDINGS_FILE}: {e}. Recalculando.\")\n",
    "\n",
    "# Se os embeddings não forem carregados, inicializa o modelo EVO e extrai-os.\n",
    "if evo_features is None:\n",
    "    print(f\"\\nA iniciar o EVO '{EVO_MODEL_NAME}'...\")\n",
    "    try:\n",
    "        # Instancia o modelo EVO. vai iniciar o download dos pesos do modelo\n",
    "        # do Hugging Face Hub se ainda não estiverem em cache local.\n",
    "        print(f\"Passo 4.1: Instanciando o modelo Evo('{EVO_MODEL_NAME}'). A descarregar os pesos do modelo.\")\n",
    "        evo_model_instance = Evo(EVO_MODEL_NAME)\n",
    "        model, tokenizer = evo_model_instance.model, evo_model_instance.tokenizer\n",
    "\n",
    "        print(f\"Passo 4.2: Modelo Evo instanciado. Parâmetros: {sum(p.numel() for p in model.parameters()) / 1e9:.2f} Bilhões.\")\n",
    "        print(f\"Passo 4.3: A mover o modelo para o dispositivo '{device}'...\")\n",
    "\n",
    "        # Move o modelo para o dispositivo selecionado (GPU ou CPU).\n",
    "        # Usa half precision (FP16) na GPU para economizar VRAM.\n",
    "        if device == 'cuda:0':\n",
    "            print(\"A carregar o modelo em half precision...\")\n",
    "            model.half().to(device)\n",
    "        else:\n",
    "            model.to(device) # Mover para CPU RAM\n",
    "\n",
    "        print(\"Passo 4.4: Modelo EVO carregado com sucesso.\")\n",
    "        if device == 'cpu':\n",
    "            print(\"AVISO: O modelo está a ser executado na CPU. A inferência será lenta.\")\n",
    "        else:\n",
    "            print(\"O modelo está a ser executado na GPU.\")\n",
    "\n",
    "        print(f\"Passo 4.5: Iniciando a extração de features com batch_size={EVO_BATCH_SIZE}...\")\n",
    "        evo_features = extract_evo_features(sequences, model, tokenizer, device, batch_size=EVO_BATCH_SIZE)\n",
    "\n",
    "        # Garante que o diretório de destino para os embeddings existe.\n",
    "        os.makedirs(DATA_PATH_FOR_EMBEDDINGS, exist_ok=True)\n",
    "        np.save(EVO_EMBEDDINGS_FILE, evo_features)\n",
    "        print(f\"\\nPasso 4.6: Embeddings do EVO gerados com sucesso e salvos em {EVO_EMBEDDINGS_FILE}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERRO CRÍTICO na secção 4: Falha ao carregar ou extrair features do modelo EVO: {e}\")\n",
    "        print(\"Verifique a sua conexão com a internet (para download do modelo) e se o 'evo-model' está instalado corretamente.\")\n",
    "        print(\"Se o problema persistir, pode haver um problema de configuração do ambiente ou de recursos inesperado.\")\n",
    "        sys.exit(1) # Sair em caso de erro crítico no carregamento/extração do EVO\n",
    "\n",
    "# --- 5. Preparar Dados para o SVM ---\n",
    "# Prepara os dados para o treinamento do modelo SVM.\n",
    "X = evo_features  # Features de entrada para o SVM (embeddings do EVO)\n",
    "y = prot_z        # Variável alvo (expressão génica)\n",
    "\n",
    "print(f\"\\nDimensão de X (features do EVO): {X.shape}\")\n",
    "print(f\"Dimensão de y (target 'prot_z'): {y.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# --- 6. Treinar o SVM (SVR - Support Vector Regressor) ---\n",
    "# Implementa a validação cruzada e a otimização de hiperparâmetros para o SVR.\n",
    "\n",
    "# Configuração da Validação Cruzada K-Fold (5 folds).\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Definição do espaço de busca para otimização de hiperparâmetros do SVR.\n",
    "# Os ranges podem ser expandidos para explorar mais combinações de hiperparâmetros.\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100, 1000, 10000], # Parâmetro de regularização\n",
    "    'gamma': ['scale', 'auto', 0.00001, 0.0001, 0.001, 0.01, 0.1, 1], # Parâmetro do kernel RBF\n",
    "    'kernel': ['rbf'] # Tipo de kernel (RBF é uma escolha comum para dados não lineares)\n",
    "}\n",
    "\n",
    "svr = SVR() # Inicializa o modelo Support Vector Regressor.\n",
    "\n",
    "print(\"\\nIniciando busca por hiperparâmetros com GridSearchCV...\")\n",
    "# GridSearchCV realiza uma busca exaustiva por todas as combinações de hiperparâmetros.\n",
    "# 'n_jobs=-1' utiliza todos os núcleos de CPU disponíveis para paralelizar a busca.\n",
    "grid_search = GridSearchCV(svr, param_grid, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X, y) # Executa a busca pelos melhores hiperparâmetros.\n",
    "\n",
    "print(f\"\\nMelhores hiperparâmetros encontrados: {grid_search.best_params_}\")\n",
    "best_svr_model = grid_search.best_estimator_ # O modelo SVR com os melhores hiperparâmetros.\n",
    "\n",
    "\n",
    "\n",
    "# --- 7. Avaliar o Modelo ---\n",
    "# Avalia o desempenho do modelo SVR otimizado usando validação cruzada.\n",
    "print(\"\\nAvaliação com validação cruzada nos melhores parâmetros...\")\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "pearson_scores = []\n",
    "\n",
    "# Itera sobre cada fold da validação cruzada.\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Treina o modelo com os melhores parâmetros no conjunto de treino do fold atual.\n",
    "    best_svr_model.fit(X_train, y_train)\n",
    "    y_pred = best_svr_model.predict(X_test) # Faz previsões no conjunto de teste do fold.\n",
    "\n",
    "    # Calcula as métricas de avaliação para o fold atual.\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Tenta calcular a correlação de Pearson, tratando casos de input constante.\n",
    "    try:\n",
    "        pearson_corr, _ = pearsonr(y_test, y_pred)\n",
    "    except ValueError:\n",
    "        pearson_corr = np.nan # Define como NaN se a correlação não for definida.\n",
    "\n",
    "    # Armazena as métricas do fold.\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "    pearson_scores.append(pearson_corr)\n",
    "\n",
    "    print(f\"Fold {fold+1}: MSE={mse:.4f}, MAE={mae:.4f}, R2={r2:.4f}, Pearson={pearson_corr:.4f}\")\n",
    "\n",
    "print(\"\\n--- Resultados Finais da Validação Cruzada ---\")\n",
    "# Apresenta a média e o desvio padrão das métricas em todos os folds.\n",
    "print(f\"MSE médio: {np.nanmean(mse_scores):.4f} +/- {np.nanstd(mse_scores):.4f}\")\n",
    "print(f\"MAE médio: {np.nanmean(mae_scores):.4f} +/- {np.nanstd(mae_scores):.4f}\")\n",
    "print(f\"R2 médio: {np.nanmean(r2_scores):.4f} +/- {np.nanstd(r2_scores):.4f}\")\n",
    "print(f\"Correlação de Pearson média: {np.nanmean(pearson_scores):.4f} +/- {np.nanstd(pearson_scores):.4f}\")\n",
    "\n",
    "# Avaliação geral no dataset completo com o melhor modelo.\n",
    "# Esta avaliação é para referência, as métricas da validação cruzada são mais robustas.\n",
    "print(\"\\n--- Métricas no Dataset Completo (com o melhor modelo treinado uma vez no dataset inteiro) ---\")\n",
    "final_model_for_full_data = grid_search.best_estimator_ # O modelo com os melhores hiperparâmetros.\n",
    "final_model_for_full_data.fit(X, y) # Treina o modelo no dataset completo.\n",
    "final_predictions = final_model_for_full_data.predict(X) # Faz previsões no dataset completo.\n",
    "\n",
    "# Calcula as métricas globais.\n",
    "global_mse = mean_squared_error(y, final_predictions)\n",
    "global_mae = mean_absolute_error(y, final_predictions)\n",
    "global_r2 = r2_score(y, final_predictions)\n",
    "try:\n",
    "    global_pearson, _ = pearsonr(y, final_predictions)\n",
    "except ValueError:\n",
    "    global_pearson = np.nan\n",
    "\n",
    "print(f\"MSE Global: {global_mse:.4f}\")\n",
    "print(f\"MAE Global: {global_mae:.4f}\")\n",
    "print(f\"R2 Global: {global_r2:.4f}\")\n",
    "print(f\"Pearson Global: {global_pearson:.4f}\")\n",
    "\n",
    "print(\"\\nFIM.\")\n"
   ],
   "id": "cd72c3f3dfebc614"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
