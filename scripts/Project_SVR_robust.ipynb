{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingRandomSearchCV, KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import joblib"
      ],
      "metadata": {
        "id": "tVEuVRfbBftA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2jiYZjxeK929",
        "outputId": "2ebd4a46-95f6-4aff-fe81-8f5aaa3c7c40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DRIVE_PATH = \"/content/drive/MyDrive\"\n",
        "\n",
        "TRAINING_DATA_FILE = os.path.join(BASE_DRIVE_PATH, \"training_data.csv\")\n",
        "\n",
        "DNABERT_EMBEDDINGS_FILE = os.path.join(BASE_DRIVE_PATH, \"dnabert_embeddings.npy\")\n",
        "\n",
        "NORMALIZATION_SCALER_FILE = os.path.join(BASE_DRIVE_PATH, \"scaler_robust.pkl\")\n",
        "\n",
        "RESULTS_OUTPUT_DIR = BASE_DRIVE_PATH\n",
        "os.makedirs(RESULTS_OUTPUT_DIR, exist_ok=True)\n",
        "RESULTS_FILE_PREFIX = \"svm_robust_optimization_results\"\n",
        "PREDICTIONS_DATA_PREFIX = \"svm_robust_predictions_data\""
      ],
      "metadata": {
        "id": "4l2WagXpBidB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Carregar Dados Originais e Embeddings Pré-Calculados\n",
        "try:\n",
        "    df = pd.read_csv(TRAINING_DATA_FILE)\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERRO: O ficheiro de dados original '{TRAINING_DATA_FILE}' não foi encontrado.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "if not all(col in df.columns for col in ['target', 'sequence', 'prot_scaled']):\n",
        "    print(\"ERRO: Colunas inesperadas no DataFrame original\")\n",
        "    sys.exit(1)\n",
        "\n",
        "y_scaled = df['prot_scaled'].values.ravel()\n",
        "\n",
        "\n",
        "scaler = None\n",
        "try:\n",
        "    scaler = joblib.load(NORMALIZATION_SCALER_FILE)\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERRO: O ficheiro RobustScaler '{NORMALIZATION_SCALER_FILE}' não foi encontrado.\")\n",
        "    sys.exit(1)\n",
        "except Exception as e:\n",
        "    print(f\"ERRO: Falha ao carregar RobustScaler de {NORMALIZATION_SCALER_FILE}: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "true_original_target_values = scaler.inverse_transform(df['prot_scaled'].values.reshape(-1, 1)).flatten()\n",
        "\n",
        "try:\n",
        "    X = np.load(DNABERT_EMBEDDINGS_FILE)\n",
        "    if X.shape[0] != len(df):\n",
        "        print(f\"AVISO: O número de amostras nos embeddings ({X.shape[0]}) não corresponde ao número de amostras no CSV ({len(df)}).\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERRO: O ficheiro de embeddings '{DNABERT_EMBEDDINGS_FILE}' não foi encontrado.\")\n",
        "    sys.exit(1)\n",
        "except Exception as e:\n",
        "    print(f\"ERRO: Falha ao carregar o ficheiro de embeddings '{DNABERT_EMBEDDINGS_FILE}': {e}\")\n",
        "    sys.exit(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh3jUVMhBmKx",
        "outputId": "f4255e50-f2d9-4f03-d74c-013e536b944d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RobustScaler from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_halving_search_cv  # Necessário para ativar HalvingRandomSearchCV\n",
        "from sklearn.model_selection import HalvingRandomSearchCV\n",
        "\n",
        "# --- 3. Treinar o SVM (SVR - Support Vector Regressor) com HalvingRandomSearchCV ---\n",
        "n_splits = 5\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "param_distributions = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
        "    'gamma': ['scale', 'auto', 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "svr = SVR()\n",
        "\n",
        "random_search = HalvingRandomSearchCV(\n",
        "    estimator=SVR(),\n",
        "    param_distributions=param_distributions,\n",
        "    factor=3,\n",
        "    resource='n_samples',\n",
        "    min_resources=500,\n",
        "    max_resources=9000,\n",
        "    n_candidates=50,\n",
        "    cv=kf,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "random_search.fit(X, y_scaled)\n",
        "\n",
        "print(f\"\\nMelhores hiperparâmetros encontrados: {random_search.best_params_}\")\n",
        "best_svr_model = random_search.best_estimator_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYZArdo2BtOx",
        "outputId": "cc2ba546-ec50-4054-c85e-a4e639e214f9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 3\n",
            "n_required_iterations: 4\n",
            "n_possible_iterations: 3\n",
            "min_resources_: 500\n",
            "max_resources_: 9000\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 50\n",
            "n_resources: 500\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 17\n",
            "n_resources: 1500\n",
            "Fitting 5 folds for each of 17 candidates, totalling 85 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 6\n",
            "n_resources: 4500\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "\n",
            "Melhores hiperparâmetros encontrados: {'kernel': 'rbf', 'gamma': 'scale', 'C': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Avaliar o Modelo ---\n",
        "print(\"\\n--- Avaliação com validação cruzada nos melhores parâmetros ---\")\n",
        "mse_scores_scaled = []\n",
        "mae_scores_scaled = []\n",
        "r2_scores_scaled = []\n",
        "pearson_scores_scaled = []\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y_scaled[train_index], y_scaled[test_index]\n",
        "\n",
        "    best_svr_model.fit(X_train, y_train)\n",
        "    y_pred_scaled = best_svr_model.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred_scaled)\n",
        "    mae = mean_absolute_error(y_test, y_pred_scaled)\n",
        "    r2 = r2_score(y_test, y_pred_scaled)\n",
        "\n",
        "    try:\n",
        "        pearson_corr, _ = pearsonr(y_test, y_pred_scaled)\n",
        "    except ValueError:\n",
        "        pearson_corr = np.nan\n",
        "\n",
        "    mse_scores_scaled.append(mse)\n",
        "    mae_scores_scaled.append(mae)\n",
        "    r2_scores_scaled.append(r2)\n",
        "    pearson_scores_scaled.append(pearson_corr)\n",
        "\n",
        "    print(f\"Fold {fold+1}: MSE={mse:.4f}, MAE={mae:.4f}, R2={r2:.4f}, Pearson={pearson_corr:.4f}\")\n",
        "\n",
        "print(\"\\n--- Resultados Finais da Validação Cruzada ---\")\n",
        "final_cv_results = {\n",
        "    \"MSE médio (escala escalada)\": f\"{np.nanmean(mse_scores_scaled):.4f} +/- {np.nanstd(mse_scores_scaled):.4f}\",\n",
        "    \"MAE médio (escala escalada)\": f\"{np.nanmean(mae_scores_scaled):.4f} +/- {np.nanstd(mae_scores_scaled):.4f}\",\n",
        "    \"R2 médio (escala escalada)\": f\"{np.nanmean(r2_scores_scaled):.4f} +/- {np.nanstd(r2_scores_scaled):.4f}\",\n",
        "    \"Correlação de Pearson média (escala escalada)\": f\"{np.nanmean(pearson_scores_scaled):.4f} +/- {np.nanstd(pearson_scores_scaled):.4f}\"\n",
        "}\n",
        "for metric, value in final_cv_results.items():\n",
        "    print(f\"{metric}: {value}\")"
      ],
      "metadata": {
        "id": "y_-xFDvbBw7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df91fb2-5432-4024-8b4d-8b0cb1720c6e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Avaliação com validação cruzada nos melhores parâmetros ---\n",
            "Fold 1: MSE=0.1978, MAE=0.3301, R2=0.6054, Pearson=0.7795\n",
            "Fold 2: MSE=0.1804, MAE=0.3168, R2=0.6087, Pearson=0.7822\n",
            "Fold 3: MSE=0.1845, MAE=0.3218, R2=0.6196, Pearson=0.7882\n",
            "Fold 4: MSE=0.1873, MAE=0.3211, R2=0.5945, Pearson=0.7740\n",
            "Fold 5: MSE=0.1732, MAE=0.3119, R2=0.6305, Pearson=0.7951\n",
            "\n",
            "--- Resultados Finais da Validação Cruzada ---\n",
            "MSE médio (escala escalada): 0.1847 +/- 0.0081\n",
            "MAE médio (escala escalada): 0.3204 +/- 0.0060\n",
            "R2 médio (escala escalada): 0.6117 +/- 0.0123\n",
            "Correlação de Pearson média (escala escalada): 0.7838 +/- 0.0073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Avaliação Final no Dataset Completo e Guardar Dados para Gráficos ---\n",
        "print(\"\\n--- Métricas no Dataset Completo (com o melhor modelo treinado uma vez no dataset inteiro) ---\")\n",
        "final_model_for_full_data = random_search.best_estimator_\n",
        "final_model_for_full_data.fit(X, y_scaled)\n",
        "final_predictions_standardized = final_model_for_full_data.predict(X)\n",
        "\n",
        "final_predictions_original = scaler.inverse_transform(final_predictions_standardized.reshape(-1, 1)).flatten()\n",
        "\n",
        "global_mse = mean_squared_error(true_original_target_values, final_predictions_original)\n",
        "global_mae = mean_absolute_error(true_original_target_values, final_predictions_original)\n",
        "global_r2 = r2_score(true_original_target_values, final_predictions_original)\n",
        "try:\n",
        "    global_pearson, _ = pearsonr(true_original_target_values.flatten(), final_predictions_original.flatten())\n",
        "except ValueError:\n",
        "    global_pearson = np.nan\n",
        "\n",
        "global_rmse = np.sqrt(global_mse)\n",
        "\n",
        "\n",
        "mean_of_original_targets = np.mean(true_original_target_values)\n",
        "\n",
        "if mean_of_original_targets != 0:\n",
        "    pmae = (global_mae / mean_of_original_targets) * 100\n",
        "    prmse = (global_rmse / mean_of_original_targets) * 100\n",
        "else:\n",
        "    pmae = np.nan\n",
        "    prmse = np.nan\n",
        "\n",
        "global_results = {\n",
        "    \"MSE Global (escala original)\": f\"{global_mse:.4f}\",\n",
        "    \"MAE Global (escala original)\": f\"{global_mae:.4f}\",\n",
        "    \"MAE Percentual (vs. Média)\": f\"{pmae:.2f}%\",\n",
        "    \"RMSE Global (escala original)\": f\"{global_rmse:.4f}\",\n",
        "    \"RMSE Percentual (vs. Média)\": f\"{prmse:.2f}%\",\n",
        "    \"R2 Global (escala original)\": f\"{global_r2:.4f}\",\n",
        "    \"Pearson Global (escala original)\": f\"{global_pearson:.4f}\"\n",
        "}\n",
        "for metric, value in global_results.items():\n",
        "    print(f\"{metric}: {value}\")\n",
        "\n",
        "\n",
        "min_original_prot = np.min(true_original_target_values)\n",
        "max_original_prot = np.max(true_original_target_values)\n",
        "std_original_prot = np.std(true_original_target_values)\n",
        "amplitude_original_prot = max_original_prot - min_original_prot\n",
        "\n",
        "print(f\"\\n--- Escala dos Valores Originais de Expressão Proteica ---\")\n",
        "print(f\"  Mínimo: {min_original_prot:.4f}\")\n",
        "print(f\"  Máximo: {max_original_prot:.4f}\")\n",
        "print(f\"  Média: {mean_of_original_targets:.4f}\")\n",
        "print(f\"  Desvio Padrão: {std_original_prot:.4f}\")\n",
        "print(f\"  Amplitude: {amplitude_original_prot:.4f}\")"
      ],
      "metadata": {
        "id": "ZQhnGrqZ_RX7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b12e651-1aa6-42b0-bffa-a0e46bef8a60"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Métricas no Dataset Completo (com o melhor modelo treinado uma vez no dataset inteiro) ---\n",
            "MSE Global (escala original): 470074974.6284\n",
            "MAE Global (escala original): 14285.4080\n",
            "MAE Percentual (vs. Média): 23.39%\n",
            "RMSE Global (escala original): 21681.2125\n",
            "RMSE Percentual (vs. Média): 35.50%\n",
            "R2 Global (escala original): 0.8879\n",
            "Pearson Global (escala original): 0.9446\n",
            "\n",
            "--- Escala dos Valores Originais de Expressão Proteica ---\n",
            "  Mínimo: 1357.1507\n",
            "  Máximo: 204059.9524\n",
            "  Média: 61077.1584\n",
            "  Desvio Padrão: 64770.3892\n",
            "  Amplitude: 202702.8018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Guardar Resultados e Dados para Gráficos ---\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "results_filename = os.path.join(RESULTS_OUTPUT_DIR, f\"{RESULTS_FILE_PREFIX}_{timestamp}.txt\")\n",
        "predictions_data_filename = os.path.join(RESULTS_OUTPUT_DIR, f\"{PREDICTIONS_DATA_PREFIX}_{timestamp}.npy\")\n",
        "model_save_filename = os.path.join(RESULTS_OUTPUT_DIR, f\"best_svm_model_robust_{timestamp}.joblib\")\n",
        "\n",
        "\n",
        "print(f\"\\n--- A guardar resultados em: {results_filename} ---\")\n",
        "with open(results_filename, 'w') as f:\n",
        "    f.write(f\"Resultados da Otimização do SVM com RobustScaler\\n\")\n",
        "    f.write(f\"Data e Hora: {timestamp}\\n\")\n",
        "    f.write(f\"----------------------------------------------------\\n\\n\")\n",
        "\n",
        "    f.write(f\"Melhores Hiperparâmetros Encontrados:\\n\")\n",
        "    for param, value in random_search.best_params_.items():\n",
        "        f.write(f\"  {param}: {value}\\n\")\n",
        "    f.write(f\"\\n\")\n",
        "\n",
        "    f.write(f\"Resultados da Validação Cruzada (Médias e Desvios Padrão - ESCALA ESCALADA (RobustScaler)):\\n\")\n",
        "    for metric, value in final_cv_results.items():\n",
        "        f.write(f\"  {metric}: {value}\\n\")\n",
        "\n",
        "    f.write(f\"Métricas no Dataset Completo (Com o melhor modelo treinado uma vez no dataset inteiro - ESCALA ORIGINAL):\\n\")\n",
        "    for metric, value in global_results.items():\n",
        "        f.write(f\"  {metric}: {value}\\n\")\n",
        "    f.write(f\"\\n\")\n",
        "    f.write(f\"--- Escala dos Valores Originais de Expressão Proteica ---\\n\")\n",
        "    f.write(f\"  Mínimo: {min_original_prot:.4f}\\n\")\n",
        "    f.write(f\"  Máximo: {max_original_prot:.4f}\\n\")\n",
        "    f.write(f\"  Média: {mean_of_original_targets:.4f}\\n\")\n",
        "    f.write(f\"  Desvio Padrão: {std_original_prot:.4f}\\n\")\n",
        "    f.write(f\"  Amplitude: {amplitude_original_prot:.4f}\\n\")\n",
        "    f.write(f\"\\n\")\n",
        "\n",
        "    f.write(f\"Informações Adicionais:\\n\")\n",
        "    f.write(f\"  Número de Amostras: {X.shape[0]}\\n\")\n",
        "    f.write(f\"  Número de Features: {X.shape[1]}\\n\")\n",
        "    f.write(f\"  Tipo de Embeddings: DNABERT\\n\")\n",
        "    f.write(f\"  Folds de Validação Cruzada: {n_splits}\\n\")\n",
        "    f.write(f\"  Iterações de RandomizedSearchCV: {random_search.n_iterations_}\\n\")\n",
        "    f.write(f\"  Ficheiro de Embeddings Usado: {os.path.basename(DNABERT_EMBEDDINGS_FILE)}\\n\")\n",
        "    f.write(f\"  Ficheiro de Modelo SVM Guardado: {os.path.basename(model_save_filename)}\\n\")\n",
        "    f.write(f\"  Ficheiro de Dados de Previsões Guardado: {os.path.basename(predictions_data_filename)}\\n\")\n",
        "    f.write(f\"  Ficheiro do Scaler Guardado: {os.path.basename(NORMALIZATION_SCALER_FILE)}\\n\") # ALTERADO\n",
        "\n",
        "\n",
        "print(f\"Resultados guardados com sucesso em {results_filename}.\")\n",
        "\n",
        "data_for_plotting = np.vstack((true_original_target_values.flatten(), final_predictions_original)).T # ALTERADO\n",
        "np.save(predictions_data_filename, data_for_plotting)\n",
        "print(f\"Valores reais (escala original) e previstos (escala original) guardados em {predictions_data_filename} para análise de gráficos.\")\n",
        "\n",
        "joblib.dump(best_svr_model, model_save_filename)\n",
        "print(f\"Melhor modelo SVM guardado em: {model_save_filename}\")\n",
        "\n",
        "print(\"\\nScript de otimização de SVM concluído.\")"
      ],
      "metadata": {
        "id": "27T0IF-UBWoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d842ca1b-c124-43b0-c1bb-3e5fe49e0bb0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- A guardar resultados em: /content/drive/MyDrive/svm_robust_optimization_results_20250620_214345.txt ---\n",
            "Resultados guardados com sucesso em /content/drive/MyDrive/svm_robust_optimization_results_20250620_214345.txt.\n",
            "Valores reais (escala original) e previstos (escala original) guardados em /content/drive/MyDrive/svm_robust_predictions_data_20250620_214345.npy para análise de gráficos.\n",
            "Melhor modelo SVM guardado em: /content/drive/MyDrive/best_svm_model_robust_20250620_214345.joblib\n",
            "\n",
            "Script de otimização de SVM concluído.\n"
          ]
        }
      ]
    }
  ]
}