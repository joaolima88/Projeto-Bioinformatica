{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opH8CxxDtFgv",
        "outputId": "6ef37685-65c2-49a7-a21b-bf852d97a226"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingRandomSearchCV, KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import joblib"
      ],
      "metadata": {
        "id": "QD6n_y3Os2mg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Configurações de Ficheiros ---\n",
        "BASE_DRIVE_PATH = \"/content/drive/MyDrive\"\n",
        "\n",
        "TRAINING_DATA_FILE = os.path.join(BASE_DRIVE_PATH, \"training_data.csv\")\n",
        "\n",
        "DNABERT_EMBEDDINGS_FILE = os.path.join(BASE_DRIVE_PATH, \"dnabert_embeddings.npy\")\n",
        "\n",
        "NORMALIZATION_SCALER_FILE = os.path.join(BASE_DRIVE_PATH, \"scaler_standard.pkl\")\n",
        "\n",
        "RESULTS_OUTPUT_DIR = BASE_DRIVE_PATH\n",
        "os.makedirs(RESULTS_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "RESULTS_FILE_PREFIX = \"svm_standard_optimization_results\"\n",
        "PREDICTIONS_DATA_PREFIX = \"svm_standard_predictions_data\""
      ],
      "metadata": {
        "id": "bXxBa8-kt70U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Carregar Dados Originais e Embeddings Pré-Calculados ---\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(TRAINING_DATA_FILE)\n",
        "    print(f\"Dados originais carregados com sucesso de {TRAINING_DATA_FILE}. Dimensão: {df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERRO: O ficheiro de dados original '{TRAINING_DATA_FILE}' não foi encontrado.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "if not all(col in df.columns for col in ['target', 'sequence', 'prot_z']):\n",
        "    print(\"ERRO: Colunas inesperadas no DataFrame original. Certifique-se de que as colunas 'target', 'sequence', e 'prot_z' existem.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "y = df['prot_z'].values.ravel()\n",
        "\n",
        "scaler = None\n",
        "try:\n",
        "    scaler = joblib.load(NORMALIZATION_SCALER_FILE)\n",
        "    print(f\"StandardScaler carregado com sucesso de: {NORMALIZATION_SCALER_FILE}\")\n",
        "    print(f\"Média do scaler para desestandardização: {scaler.mean_[0]:.4f}, Desvio Padrão: {scaler.scale_[0]:.4f}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERRO: O ficheiro StandardScaler '{NORMALIZATION_SCALER_FILE}' não foi encontrado.\")\n",
        "    print(\"É VITAL ter este ficheiro para desestandardizar as previsões corretamente.\")\n",
        "    print(\"Por favor, garanta que 'scaler_standard.pkl' está no diretório 'results/' ou ajuste o caminho.\")\n",
        "    sys.exit(1)\n",
        "except Exception as e:\n",
        "    print(f\"ERRO: Falha ao carregar StandardScaler de {NORMALIZATION_SCALER_FILE}: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "true_original_target_values = scaler.inverse_transform(df['prot_z'].values.reshape(-1, 1)).flatten()\n",
        "print(f\"Verdadeiros valores originais do target (para métricas) gerados. Exemplo (primeiros 5): {true_original_target_values[:5]}\")\n",
        "\n",
        "try:\n",
        "    X = np.load(DNABERT_EMBEDDINGS_FILE)\n",
        "    if X.shape[0] != len(df):\n",
        "        print(f\"AVISO: O número de amostras nos embeddings ({X.shape[0]}) não corresponde ao número de amostras no CSV ({len(df)}).\")\n",
        "        print(\"Pode indicar uma inconsistência nos dados. Prosseguindo, mas verifique a fonte dos embeddings.\")\n",
        "    print(f\"Embeddings DNABERT carregados com sucesso de {DNABERT_EMBEDDINGS_FILE}. Dimensão: {X.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERRO: O ficheiro de embeddings '{DNABERT_EMBEDDINGS_FILE}' não foi encontrado.\")\n",
        "    print(f\"Por favor, certifique-se de que o ficheiro .npy com os embeddings está no caminho correto e acessível.\")\n",
        "    sys.exit(1)\n",
        "except Exception as e:\n",
        "    print(f\"ERRO: Falha ao carregar o ficheiro de embeddings '{DNABERT_EMBEDDINGS_FILE}': {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "print(f\"\\nDimensão de X (features): {X.shape}\")\n",
        "print(f\"Dimensão de y (target 'prot_z' JÁ ESTANDARDIZADO): {y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFmjE7YLuSFt",
        "outputId": "cde3feea-3415-44f8-9629-ed022c49d662"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados originais carregados com sucesso de /content/drive/MyDrive/training_data.csv. Dimensão: (9336, 4)\n",
            "StandardScaler carregado com sucesso de: /content/drive/MyDrive/scaler_standard.pkl\n",
            "Média do scaler para desestandardização: 61077.1584, Desvio Padrão: 64770.3892\n",
            "Verdadeiros valores originais do target (para métricas) gerados. Exemplo (primeiros 5): [1410.9918352  1443.35117936 1559.28121553 1501.84533491 1680.76889704]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings DNABERT carregados com sucesso de /content/drive/MyDrive/dnabert_embeddings.npy. Dimensão: (9336, 768)\n",
            "\n",
            "Dimensão de X (features): (9336, 768)\n",
            "Dimensão de y (target 'prot_z' JÁ ESTANDARDIZADO): (9336,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Treinar o SVR ---\n",
        "n_splits = 5\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "param_distributions = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
        "    'gamma': ['scale', 'auto', 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
        "    'kernel': ['rbf']\n",
        "}"
      ],
      "metadata": {
        "id": "x5CpV1jjuSpC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Treinar o SVM (SVR - Support Vector Regressor) ---\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingRandomSearchCV, KFold\n",
        "\n",
        "n_splits = 5\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "param_distributions = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
        "    'gamma': ['scale', 'auto', 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "svr = SVR()\n",
        "\n",
        "print(f\"\\n--- Iniciando otimização de hiperparâmetros com HalvingRandomSearchCV ---\")\n",
        "print(f\"Utilizando {n_splits} folds de validação cruzada.\")\n",
        "print(\"Este processo utiliza múltiplos núcleos de CPU e é mais eficiente que o RandomizedSearchCV completo.\")\n",
        "\n",
        "random_search = HalvingRandomSearchCV(\n",
        "    estimator=SVR(),\n",
        "    param_distributions=param_distributions,\n",
        "    factor=3,\n",
        "    resource='n_samples',\n",
        "    min_resources=500,\n",
        "    max_resources=9000,\n",
        "    n_candidates=50,\n",
        "    cv=kf,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "random_search.fit(X, y)\n",
        "\n",
        "best_svr_model = random_search.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpp1X2Rzuthb",
        "outputId": "4cd17182-7f94-436e-a66f-615b93e9032c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iniciando otimização de hiperparâmetros com HalvingRandomSearchCV ---\n",
            "Utilizando 5 folds de validação cruzada.\n",
            "Este processo utiliza múltiplos núcleos de CPU e é mais eficiente que o RandomizedSearchCV completo.\n",
            "n_iterations: 3\n",
            "n_required_iterations: 4\n",
            "n_possible_iterations: 3\n",
            "min_resources_: 500\n",
            "max_resources_: 9000\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 50\n",
            "n_resources: 500\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 17\n",
            "n_resources: 1500\n",
            "Fitting 5 folds for each of 17 candidates, totalling 85 fits\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 6\n",
            "n_resources: 4500\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Avaliar o Modelo ---\n",
        "mse_scores = []\n",
        "mae_scores = []\n",
        "r2_scores = []\n",
        "pearson_scores = []\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    best_svr_model.fit(X_train, y_train)\n",
        "    y_pred_standardized = best_svr_model.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred_standardized)\n",
        "    mae = mean_absolute_error(y_test, y_pred_standardized)\n",
        "    r2 = r2_score(y_test, y_pred_standardized)\n",
        "\n",
        "    try:\n",
        "        pearson_corr, _ = pearsonr(y_test, y_pred_standardized)\n",
        "    except ValueError:\n",
        "        pearson_corr = np.nan\n",
        "\n",
        "    mse_scores.append(mse)\n",
        "    mae_scores.append(mae)\n",
        "    r2_scores.append(r2)\n",
        "    pearson_scores.append(pearson_corr)\n",
        "\n",
        "    print(f\"Fold {fold+1}: MSE={mse:.4f}, MAE={mae:.4f}, R2={r2:.4f}, Pearson={pearson_corr:.4f}\")\n",
        "\n",
        "print(\"\\n--- Resultados Finais da Validação Cruzada ---\")\n",
        "final_cv_results = {\n",
        "    \"MSE médio (escala estandarizada)\": f\"{np.nanmean(mse_scores):.4f} +/- {np.nanstd(mse_scores):.4f}\",\n",
        "    \"MAE médio (escala estandarizada)\": f\"{np.nanmean(mae_scores):.4f} +/- {np.nanstd(mae_scores):.4f}\",\n",
        "    \"R2 médio (escala estandarizada)\": f\"{np.nanmean(r2_scores):.4f} +/- {np.nanstd(r2_scores):.4f}\",\n",
        "    \"Correlação de Pearson média (escala estandarizada)\": f\"{np.nanmean(pearson_scores):.4f} +/- {np.nanstd(pearson_scores):.4f}\"\n",
        "}\n",
        "for metric, value in final_cv_results.items():\n",
        "    print(f\"{metric}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOsECezJuxRU",
        "outputId": "5a7c6eb9-e4b2-4af5-d711-022b6ecfb286"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: MSE=0.4183, MAE=0.4745, R2=0.6028, Pearson=0.7782\n",
            "Fold 2: MSE=0.3761, MAE=0.4515, R2=0.6118, Pearson=0.7829\n",
            "Fold 3: MSE=0.3941, MAE=0.4658, R2=0.6132, Pearson=0.7847\n",
            "Fold 4: MSE=0.3929, MAE=0.4602, R2=0.5951, Pearson=0.7725\n",
            "Fold 5: MSE=0.3666, MAE=0.4497, R2=0.6278, Pearson=0.7927\n",
            "\n",
            "--- Resultados Finais da Validação Cruzada ---\n",
            "MSE médio (escala estandarizada): 0.3896 +/- 0.0177\n",
            "MAE médio (escala estandarizada): 0.4603 +/- 0.0092\n",
            "R2 médio (escala estandarizada): 0.6101 +/- 0.0110\n",
            "Correlação de Pearson média (escala estandarizada): 0.7822 +/- 0.0068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Avaliação Final no Dataset Completo ---\n",
        "\n",
        "final_model_for_full_data = random_search.best_estimator_\n",
        "final_model_for_full_data.fit(X, y)\n",
        "final_predictions_standardized = final_model_for_full_data.predict(X)\n",
        "\n",
        "final_predictions_original = scaler.inverse_transform(final_predictions_standardized.reshape(-1, 1)).flatten()\n",
        "\n",
        "global_mse = mean_squared_error(true_original_target_values, final_predictions_original)\n",
        "global_mae = mean_absolute_error(true_original_target_values, final_predictions_original)\n",
        "global_r2 = r2_score(true_original_target_values, final_predictions_original)\n",
        "\n",
        "\n",
        "try:\n",
        "    global_pearson, _ = pearsonr(true_original_target_values.flatten(), final_predictions_original.flatten())\n",
        "except ValueError:\n",
        "    global_pearson = np.nan\n",
        "\n",
        "global_rmse = np.sqrt(global_mse)\n",
        "\n",
        "mean_of_original_targets = np.mean(true_original_target_values)\n",
        "\n",
        "if mean_of_original_targets != 0:\n",
        "    pmae = (global_mae / mean_of_original_targets) * 100\n",
        "    prmse = (global_rmse / mean_of_original_targets) * 100\n",
        "else:\n",
        "    pmae = np.nan\n",
        "    prmse = np.nan\n",
        "\n",
        "\n",
        "global_results = {\n",
        "    \"MSE Global (escala original)\": f\"{global_mse:.4f}\",\n",
        "    \"MAE Global (escala original)\": f\"{global_mae:.4f}\",\n",
        "    \"MAE Percentual (vs. Média)\": f\"{pmae:.2f}%\",\n",
        "    \"RMSE Global (escala original)\": f\"{global_rmse:.4f}\",\n",
        "    \"RMSE Percentual (vs. Média)\": f\"{prmse:.2f}%\",\n",
        "    \"R2 Global (escala original)\": f\"{global_r2:.4f}\",\n",
        "    \"Pearson Global (escala original)\": f\"{global_pearson:.4f}\"\n",
        "}\n",
        "for metric, value in global_results.items():\n",
        "    print(f\"{metric}: {value}\")\n",
        "\n",
        "\n",
        "min_original_prot = np.min(true_original_target_values)\n",
        "max_original_prot = np.max(true_original_target_values)\n",
        "mean_original_prot = np.mean(true_original_target_values)\n",
        "std_original_prot = np.std(true_original_target_values)\n",
        "amplitude_original_prot = max_original_prot - min_original_prot\n",
        "\n",
        "print(f\"\\n--- Escala dos Valores Originais de Expressão Proteica ---\")\n",
        "print(f\"  Mínimo: {min_original_prot:.4f}\")\n",
        "print(f\"  Máximo: {max_original_prot:.4f}\")\n",
        "print(f\"  Média: {mean_of_original_targets:.4f}\")\n",
        "print(f\"  Desvio Padrão: {std_original_prot:.4f}\")\n",
        "print(f\"  Amplitude: {amplitude_original_prot:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5mT1FF2u0BD",
        "outputId": "aa5b8a00-d744-48af-eb8f-88522e24e6b0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Global (escala original): 600864490.6510\n",
            "MAE Global (escala original): 15066.7422\n",
            "MAE Percentual (vs. Média): 24.67%\n",
            "RMSE Global (escala original): 24512.5374\n",
            "RMSE Percentual (vs. Média): 40.13%\n",
            "R2 Global (escala original): 0.8568\n",
            "Pearson Global (escala original): 0.9293\n",
            "\n",
            "--- Escala dos Valores Originais de Expressão Proteica ---\n",
            "  Mínimo: 1357.1507\n",
            "  Máximo: 204059.9524\n",
            "  Média: 61077.1584\n",
            "  Desvio Padrão: 64770.3892\n",
            "  Amplitude: 202702.8018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3YId26IssCJ",
        "outputId": "81669602-b114-493b-f190-6c251aea96e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- A guardar resultados em: /content/drive/MyDrive/svm_standard_optimization_results_20250620_233210.txt ---\n",
            "Resultados guardados com sucesso em /content/drive/MyDrive/svm_standard_optimization_results_20250620_233210.txt.\n",
            "Valores reais (escala original) e previstos (escala original) guardados em /content/drive/MyDrive/svm_standard_predictions_data_20250620_233210.npy para análise de gráficos.\n",
            "Melhor modelo SVR guardado em: /content/drive/MyDrive/best_svr_model_20250620_233210.joblib\n",
            "\n",
            "Script de otimização de SVM concluído.\n"
          ]
        }
      ],
      "source": [
        "# --- 6. Guardar Resultados ---\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "results_filename = os.path.join(RESULTS_OUTPUT_DIR, f\"{RESULTS_FILE_PREFIX}_{timestamp}.txt\")\n",
        "predictions_data_filename = os.path.join(RESULTS_OUTPUT_DIR, f\"{PREDICTIONS_DATA_PREFIX}_{timestamp}.npy\")\n",
        "model_save_filename = os.path.join(RESULTS_OUTPUT_DIR, f\"best_svr_model_{timestamp}.joblib\")\n",
        "\n",
        "\n",
        "print(f\"\\n--- A guardar resultados em: {results_filename} ---\")\n",
        "with open(results_filename, 'w') as f:\n",
        "    f.write(f\"Resultados da Otimização de Hiperparâmetros do SVM\\n\")\n",
        "    f.write(f\"Data e Hora: {timestamp}\\n\")\n",
        "    f.write(f\"----------------------------------------------------\\n\\n\")\n",
        "\n",
        "    f.write(f\"Melhores Hiperparâmetros Encontrados:\\n\")\n",
        "    for param, value in random_search.best_params_.items():\n",
        "        f.write(f\"  {param}: {value}\\n\")\n",
        "    f.write(f\"\\n\")\n",
        "\n",
        "    f.write(f\"Resultados da Validação Cruzada (Médias e Desvios Padrão - ESCALA ESTANDARDIZADA):\\n\")\n",
        "    for metric, value in final_cv_results.items():\n",
        "        f.write(f\"  {metric}: {value}\\n\")\n",
        "    f.write(f\"\\n\")\n",
        "\n",
        "    f.write(f\"Métricas no Dataset Completo (Com o melhor modelo treinado uma vez no dataset inteiro - ESCALA ORIGINAL):\\n\")\n",
        "    for metric, value in global_results.items():\n",
        "        f.write(f\"  {metric}: {value}\\n\")\n",
        "    f.write(f\"\\n\")\n",
        "    f.write(f\"Informações Adicionais:\\n\")\n",
        "    f.write(f\"  Número de Amostras: {X.shape[0]}\\n\")\n",
        "    f.write(f\"  Número de Features: {X.shape[1]}\\n\")\n",
        "    f.write(f\"  Tipo de Embeddings: DNABERT\\n\")\n",
        "    f.write(f\"  Folds de Validação Cruzada: {n_splits}\\n\")\n",
        "    f.write(f\"  Ficheiro de Embeddings Usado: {os.path.basename(DNABERT_EMBEDDINGS_FILE)}\\n\")\n",
        "    f.write(f\"  Ficheiro de Modelo SVR Guardado: {os.path.basename(model_save_filename)}\\n\")\n",
        "    f.write(f\"  Ficheiro de Dados de Previsões Guardado: {os.path.basename(predictions_data_filename)}\\n\")\n",
        "    f.write(f\"  Ficheiro de StandardScaler Guardado: {os.path.basename(NORMALIZATION_SCALER_FILE)}\\n\")\n",
        "\n",
        "\n",
        "print(f\"Resultados guardados com sucesso em {results_filename}.\")\n",
        "\n",
        "data_for_plotting = np.vstack((true_original_target_values.flatten(), final_predictions_original)).T\n",
        "np.save(predictions_data_filename, data_for_plotting)\n",
        "print(f\"Valores reais (escala original) e previstos (escala original) guardados em {predictions_data_filename} para análise de gráficos.\")\n",
        "\n",
        "joblib.dump(best_svr_model, model_save_filename)\n",
        "print(f\"Melhor modelo SVR guardado em: {model_save_filename}\")\n",
        "\n",
        "print(\"\\nScript de otimização de SVM concluído.\")"
      ]
    }
  ]
}